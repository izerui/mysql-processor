import os
import shutil
import sys
import time
import concurrent.futures
import re
import configparser
from typing import List, Optional, Tuple

from colorama import Fore
from tqdm import tqdm

from base import BaseShell, Mysql
from logger_config import logger

# å®šä¹‰SQLå¤´å°¾è¯­å¥
header_lines = [
    "set foreign_key_checks = 0;",  # ç¦ç”¨å¤–é”®æ£€æŸ¥
    "set unique_checks = 0;",  # ç¦ç”¨å”¯ä¸€æ€§æ£€æŸ¥
    "set autocommit=0;",  # ç¦ç”¨è‡ªåŠ¨æäº¤
    "SET SESSION sort_buffer_size = 32*1024*1024;",  # è°ƒæ•´æ’åºç¼“å†²åŒº
    "START TRANSACTION;",  # å¼€å§‹äº‹åŠ¡
]
commit_lines = [
    "commit;",
    "START TRANSACTION;",
]
footer_lines = [
    "commit;",
    "set foreign_key_checks = 1;",
    "set unique_checks = 1;",
]


class MyDump(BaseShell):
    """
    MySQLæ•°æ®åº“å¤‡ä»½å¯¼å‡ºå·¥å…·ç±»

    åŠŸèƒ½ç‰¹ç‚¹ï¼š
    1. æ”¯æŒå®Œæ•´æ•°æ®åº“ç»“æ„å¯¼å‡º
    2. æ”¯æŒå¹¶å‘å¯¼å‡ºè¡¨æ•°æ®ï¼Œæé«˜å¯¼å‡ºæ•ˆç‡
    3. æ”¯æŒå¤§æ–‡ä»¶è‡ªåŠ¨æ‹†åˆ†ï¼Œé¿å…å•ä¸ªæ–‡ä»¶è¿‡å¤§
    4. æä¾›è¯¦ç»†çš„è¿›åº¦æ˜¾ç¤ºå’Œé”™è¯¯å¤„ç†
    5. æµå¼å¤„ç†ï¼Œå†…å­˜å ç”¨ä½ï¼Œé€‚åˆå¤„ç†å¤§æ•°æ®é‡

    å¯¼å‡ºæµç¨‹ï¼š
    1. å¯¼å‡ºæ•°æ®åº“ç»“æ„ï¼ˆè¡¨ç»“æ„ã€ç´¢å¼•ç­‰ï¼‰
    2. å¹¶å‘å¯¼å‡ºæ¯ä¸ªè¡¨çš„æ•°æ®
    3. å¯¹å¤§æ–‡ä»¶è¿›è¡Œæ‹†åˆ†å¤„ç†
    4. æ·»åŠ å¿…è¦çš„SQLå¤´å°¾ä¿¡æ¯
    """

    def __init__(self, mysql: Mysql, split_threshold_mb: int = 500, threads: int = 8):
        """
        åˆå§‹åŒ–MyDumpå®ä¾‹

        Args:
            mysql: MySQLè¿æ¥é…ç½®å¯¹è±¡
            split_threshold_mb: æ–‡ä»¶æ‹†åˆ†é˜ˆå€¼ï¼ˆMBï¼‰ï¼Œè¶…è¿‡æ­¤å¤§å°çš„æ–‡ä»¶ä¼šè¢«æ‹†åˆ†
            threads: å¹¶å‘å¯¼å‡ºçº¿ç¨‹æ•°
        """
        super().__init__()
        self.mysql = mysql  # MySQLè¿æ¥é…ç½®
        self.use_pv = self._check_pv_available()  # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†pvå·¥å…·ï¼ˆè¿›åº¦æ˜¾ç¤ºï¼‰
        self.split_threshold = split_threshold_mb * 1024 * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
        self.threads = threads  # å¹¶å‘çº¿ç¨‹æ•°

    def _check_pv_available(self):
        """æ£€æŸ¥pvå·¥å…·æ˜¯å¦å¯ç”¨ï¼ˆç”¨äºè¿›åº¦æ¡æ˜¾ç¤ºï¼‰"""
        return shutil.which('pv') is not None

    def export_db(self, database: str, dump_file: str):
        """
        ä¸»å¯¼å‡ºå‡½æ•°ï¼šå¯¼å‡ºæ•´ä¸ªæ•°æ®åº“

        æ‰§è¡Œæµç¨‹ï¼š
        1. åˆ›å»ºè¾“å‡ºç›®å½•
        2. å¯¼å‡ºæ•°æ®åº“ç»“æ„
        3. è·å–æ‰€æœ‰è¡¨åˆ—è¡¨
        4. å¹¶å‘å¯¼å‡ºæ¯ä¸ªè¡¨çš„æ•°æ®
        5. æ±‡æ€»å¯¼å‡ºç»“æœ

        Args:
            database: è¦å¯¼å‡ºçš„æ•°æ®åº“åç§°
            dump_file: ä¸»SQLæ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«ç»“æ„ï¼‰
        """
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(dump_file), exist_ok=True)

            # ç¬¬ä¸€æ­¥ï¼šå¯¼å‡ºæ•°æ®åº“ç»“æ„
            if not self._export_structure(database, dump_file):
                return False

            # ç¬¬äºŒæ­¥ï¼šè·å–æ•°æ®åº“çš„æ‰€æœ‰è¡¨
            tables = self._get_all_tables(database)

            if not tables:
                logger.warning(f"æ•°æ®åº“ {database} ä¸­æ²¡æœ‰éœ€è¦å¯¼å‡ºçš„è¡¨")
                return True

            # ç¬¬ä¸‰æ­¥ï¼šå¹¶å‘å¯¼å‡ºè¡¨æ•°æ®
            success_count = self._export_tables_data(database, dump_file)
            return success_count >= 0

        except Exception as e:
            logger.error(f"å¯¼å‡ºè¿‡ç¨‹å‘ç”Ÿé”™è¯¯ - æ•°æ®åº“: {database}, é”™è¯¯: {str(e)}")
            return False

    def _export_structure(self, database: str, dump_file: str) -> bool:
        """
        å¯¼å‡ºæ•°æ®åº“ç»“æ„ï¼ˆä¸åŒ…å«æ•°æ®ï¼‰

        å¯¼å‡ºçš„ç»“æ„åŒ…æ‹¬ï¼š
        - æ•°æ®åº“åˆ›å»ºè¯­å¥
        - æ‰€æœ‰è¡¨çš„CREATE TABLEè¯­å¥
        - ç´¢å¼•å®šä¹‰
        - çº¦æŸå®šä¹‰

        Args:
            database: æ•°æ®åº“åç§°
            dump_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            bool: å¯¼å‡ºæˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
        """
        try:

            mysql_dump_exe = self.get_mysqldump_exe()
            mysql_bin_dir = self.get_mysql_bin_dir()

            # æ„å»ºmysqldumpå‘½ä»¤ï¼Œåªå¯¼å‡ºç»“æ„
            cmd = (
                f'{mysql_dump_exe} '
                f'-h {self.mysql.db_host} '
                f'-u {self.mysql.db_user} '
                f'-p\'{self.mysql.db_pass}\' '
                f'--port={self.mysql.db_port} '
                f'--ssl-mode=DISABLED ' # å¦‚æœä¸éœ€è¦SSL
                f'--protocol=TCP ' # å¼ºåˆ¶ä½¿ç”¨TCP
                f'--default-character-set=utf8 '
                f'--set-gtid-purged=OFF '  # ä¸å¯¼å‡ºGTIDä¿¡æ¯
                f'--skip-routines '  # è·³è¿‡å­˜å‚¨è¿‡ç¨‹å’Œå‡½æ•°
                f'--skip-triggers '  # è·³è¿‡è§¦å‘å™¨
                f'--skip-add-locks '  # è·³è¿‡é”è¡¨è¯­å¥
                f'--disable-keys '  # ç¦ç”¨å¤–é”®æ£€æŸ¥
                f'--skip-events '  # è·³è¿‡äº‹ä»¶
                f'--skip-set-charset '  # è·³è¿‡å­—ç¬¦é›†è®¾ç½®
                f'--add-drop-database '  # æ·»åŠ åˆ é™¤æ•°æ®åº“è¯­å¥
                f'--extended-insert '  # ä½¿ç”¨æ‰©å±•æ’å…¥æ ¼å¼
                f'--complete-insert '  # ä½¿ç”¨å®Œæ•´çš„åˆ—å
                f'--quick '  # å¿«é€Ÿå¯¼å‡ºï¼Œé€è¡Œè¯»å–
                f'--no-autocommit '  # ç¦ç”¨è‡ªåŠ¨æäº¤
                f'--single-transaction '  # ä½¿ç”¨ä¸€è‡´æ€§å¿«ç…§
                f'--skip-lock-tables '  # ä¸é”è¡¨
                f'--compress '  # å‹ç¼©ä¼ è¾“
                f'--skip-tz-utc '  # ä¸è®¾ç½®æ—¶åŒº
                f'--max-allowed-packet=256M '  # æœ€å¤§åŒ…å¤§å°
                f'--net-buffer-length=1048576 '  # ç½‘ç»œç¼“å†²åŒºå¤§å°
                f'--no-data '  # å…³é”®ï¼šä¸å¯¼å‡ºæ•°æ®
                f'--databases {database}'
            )

            full_command = f'{cmd} > {dump_file}'
            success, exit_code, output = self._exe_command(full_command, cwd=mysql_bin_dir)

            if not success:
                raise RuntimeError(f"æ•°æ®åº“ç»“æ„å¯¼å‡ºå¤±è´¥ï¼Œexit code: {exit_code}")

            return True

        except Exception as e:
            logger.error(f"æ•°æ®åº“ç»“æ„å¯¼å‡ºå¤±è´¥ - æ•°æ®åº“: {database}, é”™è¯¯: {str(e)}")
            return False

    def _export_tables_data(self, database: str, dump_file: str) -> int:
        """
        å¹¶å‘å¯¼å‡ºæ‰€æœ‰è¡¨çš„æ•°æ®

        ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¯¼å‡ºæ¯ä¸ªè¡¨çš„æ•°æ®ï¼Œæä¾›å®æ—¶è¿›åº¦æ˜¾ç¤º

        Args:
            database: æ•°æ®åº“åç§°
            dump_file: ä¸»SQLæ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºç¡®å®šè¾“å‡ºç›®å½•ï¼‰

        Returns:
            int: æˆåŠŸå¯¼å‡ºçš„è¡¨æ•°é‡
        """
        # ä¸ºæ¯ä¸ªæ•°æ®åº“åˆ›å»ºå•ç‹¬çš„æ–‡ä»¶å¤¹å­˜æ”¾è¡¨æ•°æ®
        db_folder = os.path.join(os.path.dirname(dump_file), database)
        os.makedirs(db_folder, exist_ok=True)

        # è·å–æ•°æ®åº“çš„æ‰€æœ‰è¡¨
        tables = self._get_all_tables(database)
        if not tables:
            logger.warning(f"æ•°æ®åº“ {database} ä¸­æ²¡æœ‰éœ€è¦å¯¼å‡ºçš„è¡¨")
            return 0

        success_count = 0
        failed_tables = []
        exported_total_size = 0.0  # å·²å¯¼å‡ºçš„æ€»å¤§å°
        export_start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´

        # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡
        with tqdm(total=len(tables), desc=f"{Fore.MAGENTA}ğŸ“Š å¹¶è¡Œ[{self.threads}]å¯¼å‡º {database} è¡¨æ•°æ®", unit="è¡¨",
                  dynamic_ncols=True, disable=False,
                  file=sys.stdout, ascii=True) as pbar:
            def update_progress(result, table_name):
                """æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º"""
                nonlocal exported_total_size
                if result['success']:
                    # è®¡ç®—å·²å¯¼å‡ºçš„æ€»å¤§å°
                    exported_total_size = self._get_exported_files_size(db_folder)
                    # è®¡ç®—ä»å¼€å§‹åˆ°ç°åœ¨çš„æ•´ä½“å¹³å‡é€Ÿåº¦
                    elapsed_time = time.time() - export_start_time
                    overall_speed = f"{exported_total_size / elapsed_time:.1f}MB/s" if elapsed_time > 0 else "0.0MB/s"
                    pbar.set_postfix_str(
                        f"âœ“ {table_name} ({result['original_size_mb']:.1f}MB) å¹³å‡é€Ÿåº¦: {overall_speed} å·²å¯¼å‡º: {exported_total_size:.1f}MB")
                else:
                    exported_total_size = self._get_exported_files_size(db_folder)
                    # å³ä½¿å¤±è´¥ä¹Ÿè®¡ç®—æ•´ä½“å¹³å‡é€Ÿåº¦
                    elapsed_time = time.time() - export_start_time
                    overall_speed = f"{exported_total_size / elapsed_time:.1f}MB/s" if elapsed_time > 0 else "0.0MB/s"
                    pbar.set_postfix_str(
                        f"âœ— {table_name} å¹³å‡é€Ÿåº¦: {overall_speed} å·²å¯¼å‡º: {exported_total_size:.1f}MB")
                pbar.update(1)
                return result

            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¯¼å‡º
            with concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as pool:
                # æäº¤æ‰€æœ‰å¯¼å‡ºä»»åŠ¡
                futures = []
                for table in tables:
                    table_file = os.path.join(db_folder, f"{table}.sql")
                    future = pool.submit(
                        self._export_table_data,
                        database,
                        table,
                        table_file,
                    )
                    # æ·»åŠ å›è°ƒæ¥æ›´æ–°è¿›åº¦
                    future.add_done_callback(
                        lambda f, t=table: update_progress(f.result(), t)
                    )
                    futures.append(future)

                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                concurrent.futures.wait(futures)

                # æ”¶é›†æœ€ç»ˆç»“æœ
                for future, table in zip(futures, tables):
                    try:
                        result = future.result()
                        if result['success']:
                            success_count += 1
                        else:
                            failed_tables.append(table)
                            logger.error(f"è¡¨å¯¼å‡ºå¤±è´¥ - æ•°æ®åº“: {database}, è¡¨: {table}, é”™è¯¯: {result['error']}")
                    except Exception as e:
                        failed_tables.append(table)
                        logger.error(f"è¡¨å¯¼å‡ºå¼‚å¸¸ - æ•°æ®åº“: {database}, è¡¨: {table}, é”™è¯¯: {str(e)}")

        return success_count

    def _get_exported_files_size(self, db_folder: str) -> float:
        """
        è®¡ç®—å·²å¯¼å‡ºçš„SQLæ–‡ä»¶æ€»å¤§å°

        Args:
            db_folder: æ•°æ®åº“å¯¼å‡ºæ–‡ä»¶å¤¹è·¯å¾„

        Returns:
            float: æ€»å¤§å°ï¼ˆMBï¼‰
        """
        try:
            total_size = 0.0
            if os.path.exists(db_folder):
                for filename in os.listdir(db_folder):
                    if filename.endswith('.sql'):
                        file_path = os.path.join(db_folder, filename)
                        if os.path.isfile(file_path):
                            total_size += os.path.getsize(file_path) / 1024 / 1024
            return total_size
        except Exception as e:
            logger.error(f"è®¡ç®—å¯¼å‡ºæ–‡ä»¶æ€»å¤§å°å¤±è´¥: {str(e)}")
            return 0.0

    def _export_table_data(self, database: str, table: str, table_file: str) -> dict:
        """
        å¯¼å‡ºå•ä¸ªè¡¨çš„æ•°æ®

        å¤„ç†é€»è¾‘ï¼š
        1. ä½¿ç”¨mysqldumpå¯¼å‡ºè¡¨æ•°æ®
        2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åŒ…å«æœ‰æ•ˆæ•°æ®ï¼ˆINSERTè¯­å¥ï¼‰
        3. å¯¹å¤§æ–‡ä»¶è¿›è¡Œæ‹†åˆ†å¤„ç†
        4. å¯¹å°æ–‡ä»¶æ·»åŠ å¤´å°¾ä¿¡æ¯

        Args:
            database: æ•°æ®åº“åç§°
            table: è¡¨åç§°
            table_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            dict: åŒ…å«å¯¼å‡ºç»“æœçš„å­—å…¸
                - success: æ˜¯å¦æˆåŠŸ
                - duration: è€—æ—¶ï¼ˆç§’ï¼‰
                - size_mb: æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
                - error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        start_time = time.time()

        try:
            mysql_dump_exe = self.get_mysqldump_exe()
            mysql_bin_dir = self.get_mysql_bin_dir()

            # æ„å»ºmysqldumpå‘½ä»¤ï¼Œåªå¯¼å‡ºæ•°æ®
            cmd = (
                f'{mysql_dump_exe} '
                f'-h {self.mysql.db_host} '
                f'-u {self.mysql.db_user} '
                f'-p"{self.mysql.db_pass}" '
                f'--port={self.mysql.db_port} '
                f'--ssl-mode=DISABLED ' # å¦‚æœä¸éœ€è¦SSL
                f'--protocol=TCP ' # å¼ºåˆ¶ä½¿ç”¨TCP
                f'--default-character-set=utf8 '
                f'--set-gtid-purged=OFF '
                f'--skip-routines '
                f'--skip-triggers '
                f'--skip-add-locks '
                f'--disable-keys '
                f'--skip-events '
                f'--skip-set-charset '
                f'--extended-insert '
                f'--complete-insert '
                f'--quick '
                f'--no-autocommit '
                f'--single-transaction '
                f'--skip-lock-tables '
                f'--no-autocommit '
                f'--compress '
                f'--skip-tz-utc '
                f'--max-allowed-packet=256M '
                f'--net-buffer-length=1048576 '
                f'--no-create-info '
                f'--skip-set-charset '
                f'--skip-comments '
                f'--compact '
                f'--set-gtid-purged=OFF '
                f'--quick '
                f'{database} {table}'
            )

            # ç›´æ¥å¯¼å‡ºåˆ°è¡¨å.sqlæ–‡ä»¶
            full_command = f'{cmd} > {table_file}'

            success, exit_code, output = self._exe_command(
                full_command, cwd=mysql_bin_dir
            )

            if not success:
                raise RuntimeError(f"è¡¨æ•°æ®å¯¼å‡ºå¤±è´¥ï¼Œexit code: {exit_code}")

            # å¤„ç†å¯¼å‡ºçš„æ–‡ä»¶
            if os.path.exists(table_file):
                file_size = os.path.getsize(table_file)

                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åŒ…å«INSERT INTOè¯­å¥
                has_insert = self._check_has_insert_sql(table_file)

                if not has_insert:
                    # å¦‚æœæ²¡æœ‰INSERT INTOè¯­å¥ï¼Œè¯´æ˜è¡¨ä¸ºç©ºï¼Œåˆ é™¤æ–‡ä»¶
                    os.remove(table_file)
                    return {
                        'success': True,
                        'duration': time.time() - start_time,
                        'size_mb': 0,
                        'original_size_mb': 0
                    }

                # å¤„ç†å¤§æ–‡ä»¶æ‹†åˆ†
                if file_size > self.split_threshold:
                    temp_file = f"{table_file}.tmp"
                    os.rename(table_file, temp_file)
                    self._split_large_file(temp_file, table_file, self.split_threshold)
                    os.remove(temp_file)
                    file_size_mb = file_size / 1024 / 1024
                else:
                    # å°æ–‡ä»¶ï¼Œæ·»åŠ å¤´å°¾ä¿¡æ¯
                    self._add_header_footer_to_file(table_file)
                    file_size_mb = file_size / 1024 / 1024

                return {
                    'success': True,
                    'duration': time.time() - start_time,
                    'size_mb': file_size_mb,
                    'original_size_mb': file_size_mb
                }
            else:
                # ç©ºæ–‡ä»¶ï¼Œä¸åˆ›å»º
                return {
                    'success': True,
                    'duration': time.time() - start_time,
                    'size_mb': 0
                }

        except Exception as e:
            # æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ–‡ä»¶
            if os.path.exists(table_file):
                os.remove(table_file)
            return {
                'success': False,
                'duration': time.time() - start_time,
                'error': str(e),
                'original_size_mb': 0
            }

    def _get_all_tables(self, database: str) -> List[str]:
        """
        è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨å

        Args:
            database: æ•°æ®åº“åç§°

        Returns:
            List[str]: è¡¨ååˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
        """
        try:
            import pymysql
            connection = pymysql.connect(
                host=self.mysql.db_host,
                user=self.mysql.db_user,
                password=self.mysql.db_pass,
                port=int(self.mysql.db_port),
                database=database,
                charset='utf8'
            )

            with connection.cursor() as cursor:
                cursor.execute("SHOW TABLES")
                tables = [row[0] for row in cursor.fetchall()]

            connection.close()
            return sorted(tables)

        except Exception as e:
            logger.error(f"è·å–è¡¨åˆ—è¡¨å¤±è´¥ - æ•°æ®åº“: {database}, é”™è¯¯: {str(e)}")
            return []

    def _split_large_file(self, temp_file: str, base_filename: str, max_size: int):
        """
        ä½¿ç”¨æµå¼å¤„ç†æ‹†åˆ†å¤§æ–‡ä»¶ï¼Œé¿å…å†…å­˜å ç”¨

        æµå¼æ‹†åˆ†ç­–ç•¥ï¼š
        1. ç›´æ¥å¤„ç†ç”Ÿæˆå™¨ï¼šä¸æ”¶é›†æ‰€æœ‰INSERTè¡Œåˆ°å†…å­˜
        2. åˆ†å—å†™å…¥ï¼šcurrent_linesåªä¿å­˜å½“å‰æ–‡ä»¶å†…å®¹
        3. åŠæ—¶é‡Šæ”¾ï¼šå†™å®Œä¸€ä¸ªæ–‡ä»¶ç«‹å³æ¸…ç©ºç¼“å­˜
        4. ç¼–ç å…¼å®¹ï¼šä¿ç•™UTF-8/Latin-1å¤„ç†é€»è¾‘
        5. æ¯50è¡ŒINSERTåæ·»åŠ commit_lines

        å†…å­˜æ§åˆ¶ï¼š
        - å³°å€¼å†…å­˜ = å•ä¸ªæ–‡ä»¶æœ€å¤§å†…å®¹ + 64KBç¼“å†²åŒº
        - ä¸åŸå§‹æ–‡ä»¶å¤§å°æ— å…³ï¼Œé€‚åˆå¤„ç†GBçº§æ–‡ä»¶

        Args:
            temp_file: ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            base_filename: åŸºç¡€æ–‡ä»¶å
            max_size: æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        """
        base_name_without_ext = os.path.splitext(base_filename)[0]
        ext = os.path.splitext(base_filename)[1]

        # è½¬æ¢ä¸ºå­—èŠ‚
        max_bytes = max_size
        file_counter = 1

        header_bytes = ('\n'.join(header_lines) + '\n').encode('utf-8')
        footer_bytes = ('\n'.join(footer_lines) + '\n').encode('utf-8')
        commit_bytes = ('\n'.join(commit_lines) + '\n').encode('utf-8')

        # è®¡ç®—å¤´å°¾å ç”¨çš„ç©ºé—´
        header_size = len(header_bytes)
        footer_size = len(footer_bytes)
        commit_size = len(commit_bytes)
        effective_max_bytes = max_bytes - header_size - footer_size - commit_size

        try:
            # æµå¼å¤„ç†INSERT INTOè¡Œï¼Œé¿å…å†…å­˜å ç”¨
            insert_lines = self._iter_insert_lines(temp_file)

            # å¼€å§‹æ‹†åˆ†æ–‡ä»¶ - ä½¿ç”¨çœŸæ­£çš„æµå¼å¤„ç†
            current_lines = []
            current_size = 0
            insert_count = 0

            for line in insert_lines:
                # å¤„ç†æ¯ä¸€è¡Œ - ä¿ç•™åŸæœ‰çš„ç¼–ç å¤„ç†é€»è¾‘
                if not line.endswith('\n'):
                    line += '\n'
                try:
                    byte_line = line.encode('utf-8')
                except UnicodeEncodeError:
                    byte_line = line.encode('latin-1')

                line_size = len(byte_line)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºæ–°æ–‡ä»¶
                if current_size + line_size > effective_max_bytes and current_lines:
                    # å†™å…¥å½“å‰æ–‡ä»¶
                    current_output_file = f"{base_name_without_ext}.part{file_counter:03d}{ext}"
                    with open(current_output_file, 'wb') as output_handle:
                        output_handle.write(header_bytes)
                        for line_data in current_lines:
                            output_handle.write(line_data)
                        output_handle.write(footer_bytes)

                    # é‡ç½®è®¡æ•°å™¨
                    file_counter += 1
                    current_lines = []
                    current_size = 0
                    insert_count = 0

                current_lines.append(byte_line)
                current_size += line_size
                insert_count += 1

                # æ¯50è¡ŒINSERTåæ·»åŠ commit_lines
                if insert_count % 50 == 0 and current_lines:
                    # æ·»åŠ commitè¯­å¥ï¼ˆé™¤äº†æœ€åä¸€ä¸ªæ–‡ä»¶çš„æœ€åä¸€ç»„ï¼‰
                    current_lines.append(commit_bytes)
                    current_size += commit_size

            # å†™å…¥æœ€åä¸€ä¸ªæ–‡ä»¶
            if current_lines:
                current_output_file = f"{base_name_without_ext}.part{file_counter:03d}{ext}"
                with open(current_output_file, 'wb') as output_handle:
                    output_handle.write(header_bytes)
                    for line_data in current_lines:
                        output_handle.write(line_data)
                    output_handle.write(footer_bytes)
                file_counter += 1

            return file_counter - 1

        except Exception as e:
            logger.error(f"æ‹†åˆ†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise

    def _check_has_insert_sql(self, file_path: str) -> bool:
        """
        æ£€æŸ¥SQLæ–‡ä»¶æ˜¯å¦åŒ…å«INSERT INTOè¯­å¥

        Args:
            file_path: SQLæ–‡ä»¶è·¯å¾„

        Returns:
            bool: åŒ…å«INSERTè¯­å¥è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        try:
            for _ in self._iter_insert_lines(file_path):
                return True
            return False
        except Exception as e:
            logger.error(f"æ£€æŸ¥SQLæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False

    def _iter_insert_lines(self, file_path: str):
        """
        ç”Ÿæˆå™¨ä¸­é€ä¸ªäº§ç”ŸINSERT INTOè¡Œï¼Œå®ç°çœŸæ­£çš„æµå¼å¤„ç†

        æµå¼å¤„ç†æœºåˆ¶ï¼š
        1. 64KBå—è¯»å–ï¼šé¿å…ä¸€æ¬¡æ€§åŠ è½½å¤§æ–‡ä»¶åˆ°å†…å­˜
        2. é€è¡Œè§£ç ï¼šæ”¯æŒUTF-8å’ŒLatin-1ç¼–ç å›é€€
        3. ç”Ÿæˆå™¨æ¨¡å¼ï¼šæŒ‰éœ€äº§ç”ŸINSERTè¯­å¥ï¼Œå†…å­˜å ç”¨æ’å®š
        4. äºŒè¿›åˆ¶å¤„ç†ï¼šä¿ç•™åŸå§‹æ•°æ®å®Œæ•´æ€§

        Args:
            file_path: SQLæ–‡ä»¶è·¯å¾„

        Yields:
            str: æ¯ä¸ªINSERT INTOè¡Œï¼ˆå·²è§£ç ä¸ºå­—ç¬¦ä¸²ï¼‰
        """
        try:
            with open(file_path, 'rb') as f:
                buffer = b''
                while True:
                    chunk = f.read(65536)  # 64KB chunks
                    if not chunk:
                        # å¤„ç†å‰©ä½™ç¼“å†²åŒº
                        if buffer:
                            lines = buffer.split(b'\n')
                            for line_bytes in lines:
                                if line_bytes.strip():
                                    try:
                                        line = line_bytes.decode('utf-8').strip()
                                    except UnicodeDecodeError:
                                        line = line_bytes.decode('latin-1').strip()
                                    if line.upper().startswith('INSERT INTO'):
                                        yield line
                        break

                    buffer += chunk
                    lines = buffer.split(b'\n')
                    buffer = lines[-1]  # ä¿ç•™ä¸å®Œæ•´çš„è¡Œ

                    for line_bytes in lines[:-1]:
                        line_bytes = line_bytes.strip()
                        if line_bytes:
                            try:
                                line = line_bytes.decode('utf-8').strip()
                            except UnicodeDecodeError:
                                line = line_bytes.decode('latin-1').strip()
                            if line.upper().startswith('INSERT INTO'):
                                yield line
        except Exception as e:
            logger.error(f"æ”¶é›†INSERT INTOè¡Œæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise

    def _add_header_footer_to_file(self, file_path: str) -> bool:
        """
        ç»™æ–‡ä»¶æ·»åŠ å¤´å°¾ä¿¡æ¯ï¼Œä½¿ç”¨æµå¼å¤„ç†ä¿ç•™INSERT INTOè¯­å¥

        æµå¼å¤„ç†ç‰¹ç‚¹ï¼š
        1. å¤ç”¨ _iter_insert_lines ç”Ÿæˆå™¨ï¼Œä¸é‡å¤å†…å­˜å ç”¨
        2. ä¸´æ—¶æ–‡ä»¶æ–¹å¼ï¼Œä¿è¯æ•°æ®å®‰å…¨
        3. é€è¡Œå†™å…¥ï¼Œå†…å­˜å ç”¨æ’å®š
        4. ä¿æŒåŸå§‹ç¼–ç å¤„ç†é€»è¾‘
        5. æ¯50è¡ŒINSERTåæ·»åŠ commit_lines

        Args:
            file_path: SQLæ–‡ä»¶è·¯å¾„

        Returns:
            bool: å¤„ç†æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
        """
        try:
            header = '\n'.join(header_lines) + "\n"
            footer = '\n'.join(footer_lines) + "\n"
            commit = '\n'.join(commit_lines) + "\n"

            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶æ–¹å¼å¤„ç†ï¼Œé¿å…æ•°æ®ä¸¢å¤±
            temp_file = file_path + '.tmp'

            # æ”¶é›†æ‰€æœ‰INSERT INTOè¡Œ
            insert_lines = list(self._iter_insert_lines(file_path))
            total_lines = len(insert_lines)

            # å†™å…¥å¤„ç†åçš„å†…å®¹
            with open(temp_file, 'w', encoding='utf-8') as out_f:
                out_f.write(header)

                for i, line in enumerate(insert_lines):
                    out_f.write('\n' + line)

                    # æ¯50è¡ŒINSERTåæ·»åŠ commit_linesï¼ˆä¸æ˜¯æœ€åä¸€è¡Œï¼‰
                    if (i + 1) % 50 == 0 and (i + 1) < total_lines:
                        out_f.write('\n' + commit)

                out_f.write('\n' + footer)

            # åŸå­æ›¿æ¢åŸæ–‡ä»¶
            os.replace(temp_file, file_path)
            return True

        except Exception as e:
            logger.error(f"æ·»åŠ å¤´å°¾ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            temp_file = file_path + '.tmp'
            if os.path.exists(temp_file):
                os.remove(temp_file)
            return False
