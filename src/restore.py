import os
import sys
import time
import concurrent.futures
from pathlib import Path
from typing import List, Optional, Dict, Any
from colorama import Fore
from base import BaseShell, Mysql
from logger_config import logger


class MyRestore(BaseShell):
    """
    ä»SQLæ–‡ä»¶å¯¼å…¥åˆ°MySQLæ•°æ®åº“ - é‡æ„ç‰ˆ
    æä¾›æ¸…æ™°çš„è¿›åº¦æ˜¾ç¤ºå’Œç»“æ„åŒ–æ—¥å¿—
    """

    def __init__(self, mysql: Mysql):
        super().__init__()
        self.mysql = mysql

    def restore_db(self, database: str, dump_folder: str) -> bool:
        """
        ä»SQLæ–‡ä»¶å¯¼å…¥æ•´ä¸ªæ•°æ®åº“ï¼Œæä¾›æ¸…æ™°çš„è¿›åº¦æ˜¾ç¤º
        :param database: æ•°æ®åº“å
        :param dump_folder: å¯¼å‡ºæ–‡ä»¶å¤¹è·¯å¾„
        :return: bool æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
        """
        start_time = time.time()
        logger.log_database_start(database, "å¯¼å…¥")

        try:
            # 1. å¯¼å…¥æ•°æ®åº“ç»“æ„
            structure_file = os.path.join(dump_folder, f"{database}.sql")
            if not os.path.exists(structure_file):
                logger.error(f"æ•°æ®åº“ç»“æ„æ–‡ä»¶ä¸å­˜åœ¨: {structure_file}")
                return False

            logger.info(f"å¼€å§‹å¯¼å…¥æ•°æ®åº“ç»“æ„...")
            if not self._import_structure(structure_file, database):
                return False

            # 2. è·å–æ‰€æœ‰è¡¨æ•°æ®æ–‡ä»¶
            db_data_folder = os.path.join(dump_folder, database)
            if not os.path.exists(db_data_folder):
                logger.info(f"â„¹ï¸ æ•°æ®åº“ {database} æ— è¡¨æ•°æ®æ–‡ä»¶ï¼Œè·³è¿‡è¡¨æ•°æ®å¯¼å…¥")
                logger.log_database_complete(database, "å¯¼å…¥", time.time() - start_time)
                return True

            # æ”¶é›†æ‰€æœ‰æ•°æ®æ–‡ä»¶
            data_files = self._collect_data_files(db_data_folder)
            if not data_files:
                logger.info(f"â„¹ï¸ æ•°æ®åº“ {database} æ— æœ‰æ•ˆè¡¨æ•°æ®éœ€è¦å¯¼å…¥")
                logger.log_database_complete(database, "å¯¼å…¥", time.time() - start_time)
                return True

            # 3. å¹¶å‘å¯¼å…¥è¡¨æ•°æ®
            logger.info(f"å¼€å§‹å¹¶å‘å¯¼å…¥ {len(data_files)} ä¸ªè¡¨æ•°æ®æ–‡ä»¶...")
            success_count = self._import_tables_data(database, data_files)

            total_duration = time.time() - start_time
            if success_count == len(data_files):
                logger.log_database_complete(database, "å¯¼å…¥", total_duration)
                return True
            else:
                logger.error(f"å¯¼å…¥å¤±è´¥: {len(data_files) - success_count} ä¸ªæ–‡ä»¶å¯¼å…¥å¤±è´¥")
                return False

        except Exception as e:
            logger.error(f"å¯¼å…¥è¿‡ç¨‹å‘ç”Ÿé”™è¯¯ - æ•°æ®åº“: {database}, é”™è¯¯: {str(e)}")
            return False

    def _import_structure(self, structure_file: str, database: str) -> bool:
        """å¯¼å…¥æ•°æ®åº“ç»“æ„"""
        try:
            file_size = os.path.getsize(structure_file) / 1024 / 1024
            logger.info(f"å¯¼å…¥æ•°æ®åº“ç»“æ„æ–‡ä»¶ ({file_size:.1f}MB)")

            start_time = time.time()
            success = self._execute_import(structure_file, database)

            if success:
                duration = time.time() - start_time
                logger.info(f"\n{Fore.GREEN}   ğŸ“Š æ•°æ®åº“ç»“æ„å¯¼å…¥å®Œæˆ")
                logger.info(f"{Fore.GREEN}   â° è€—æ—¶: {duration:.2f}ç§’")
                logger.info(f"{Fore.GREEN}   {'=' * 30}\n")
                return True
            else:
                return False

        except Exception as e:
            logger.error(f"æ•°æ®åº“ç»“æ„å¯¼å…¥å¤±è´¥ - æ•°æ®åº“: {database}, é”™è¯¯: {str(e)}")
            return False

    def _collect_data_files(self, db_data_folder: str) -> List[str]:
        """æ”¶é›†æ‰€æœ‰éœ€è¦å¯¼å…¥çš„æ•°æ®æ–‡ä»¶ï¼ŒåŒ…æ‹¬æ‹†åˆ†åçš„æ–‡ä»¶"""
        data_files = []

        for file in sorted(os.listdir(db_data_folder)):
            if file.endswith('.sql'):
                file_path = os.path.join(db_data_folder, file)
                file_size = os.path.getsize(file_path)

                if file_size > 0:
                    data_files.append(file_path)
                else:
                    logger.info(f"â­ï¸ è·³è¿‡ç©ºæ–‡ä»¶: {file}")

        return data_files

    def _import_tables_data(self, database: str, data_files: List[str]) -> int:
        """å¹¶å‘å¯¼å…¥æ‰€æœ‰è¡¨æ•°æ®"""
        import_start = time.time()
        success_count = 0
        failed_files = []

        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as pool:
            # æäº¤æ‰€æœ‰å¯¼å…¥ä»»åŠ¡
            futures = []
            for idx, sql_file in enumerate(data_files):
                future = pool.submit(
                    self._import_single_table,
                    sql_file, database, idx + 1, len(data_files)
                )
                futures.append((sql_file, future))

            # æ”¶é›†ç»“æœ - ä½¿ç”¨as_completedå®ç°å¼‚æ­¥æ˜¾ç¤º
            for future in concurrent.futures.as_completed([f for _, f in futures]):
                sql_file = None
                try:
                    # æ‰¾åˆ°å¯¹åº”çš„æ–‡ä»¶å
                    sql_file = next(f_path for f_path, f_obj in futures if f_obj == future)
                    result = future.result()
                    if result['success']:
                        success_count += 1
                        logger.log_table_complete(
                            database,
                            os.path.basename(sql_file).replace('.sql', ''),
                            result['duration'],
                            result['size_mb']
                        )
                    else:
                        failed_files.append(os.path.basename(sql_file))
                        logger.error(f"æ–‡ä»¶å¯¼å…¥å¤±è´¥ - æ–‡ä»¶: {os.path.basename(sql_file)}, é”™è¯¯: {result['error']}")
                except Exception as e:
                    if sql_file:
                        failed_files.append(os.path.basename(sql_file))
                    logger.error(f"æ–‡ä»¶å¯¼å…¥å¼‚å¸¸ - æ–‡ä»¶: {os.path.basename(sql_file) or 'unknown'}, é”™è¯¯: {str(e)}")

                # æ›´æ–°æ‰¹é‡è¿›åº¦
                progress = (success_count + len(failed_files)) / len(data_files) * 100
                logger.log_batch_progress(
                    "è¡¨æ•°æ®å¯¼å…¥",
                    success_count + len(failed_files),
                    len(data_files),
                    len(failed_files)
                )

        import_duration = time.time() - import_start
        logger.info(f"ğŸ“Š è¡¨æ•°æ®å¯¼å…¥ç»Ÿè®¡ - æˆåŠŸ: {success_count}, å¤±è´¥: {len(failed_files)}, æ€»è®¡: {len(data_files)}, è€—æ—¶: {import_duration:.1f}s")

        if failed_files:
            logger.error(f"å¯¼å…¥å¤±è´¥æ–‡ä»¶åˆ—è¡¨: {', '.join(failed_files)}")

        return success_count

    def _import_single_table(self, sql_file: str, database: str,
                           current_num: int, total_files: int) -> Dict[str, Any]:
        """å¯¼å…¥å•ä¸ªè¡¨çš„æ•°æ®"""
        start_time = time.time()

        try:
            file_size = os.path.getsize(sql_file)
            file_size_mb = file_size / 1024 / 1024
            table_name = os.path.basename(sql_file).replace('.sql', '')

            success = self._execute_import(sql_file, database)

            return {
                'success': success,
                'duration': time.time() - start_time,
                'size_mb': file_size_mb,
                'error': None if success else "å¯¼å…¥æ‰§è¡Œå¤±è´¥"
            }

        except Exception as e:
            return {
                'success': False,
                'duration': time.time() - start_time,
                'size_mb': 0,
                'error': str(e)
            }

    def _execute_import(self, sql_file: str, database: str) -> bool:
        """æ‰§è¡Œå•ä¸ªSQLæ–‡ä»¶çš„å¯¼å…¥"""
        try:
            mysql_path = self._get_mysql_exe()
            mysql_bin_dir = os.path.dirname(mysql_path)

            # æ„å»ºä¼˜åŒ–çš„mysqlå‘½ä»¤
            init_commands = [
                "SET autocommit=0",
                "SET foreign_key_checks=0",
                "SET unique_checks=0",
                "SET SESSION innodb_lock_wait_timeout=3600"
            ]
            init_command_str = ";".join(init_commands)

            cmd = (
                f'{mysql_path} '
                f'-h {self.mysql.db_host} '
                f'-u {self.mysql.db_user} '
                f'-p\'{self.mysql.db_pass}\' '
                f'--port={self.mysql.db_port} '
                f'--default-character-set=utf8 '
                f'--max_allowed_packet=268435456 '
                f'--net_buffer_length=1048576 '
                f'--init-command="{init_command_str}"'
                f' {database}'
            )

            import_command = f'{cmd} < "{sql_file}"'

            start_time = time.time()
            success, exit_code, output = self._exe_command(
                import_command, cwd=mysql_bin_dir
            )
            duration = time.time() - start_time

            if success:
                # å¯¼å…¥æˆåŠŸåæäº¤äº‹åŠ¡
                commit_cmd = (
                    f'{mysql_path} '
                    f'-h {self.mysql.db_host} '
                    f'-u {self.mysql.db_user} '
                    f'-p\'{self.mysql.db_pass}\' '
                    f'--port={self.mysql.db_port} '
                    f'--default-character-set=utf8 '
                    f'--execute="COMMIT; SET foreign_key_checks=1; SET unique_checks=1; SET autocommit=1;"'
                    f' {database}'
                )

                commit_success, commit_exit_code, commit_output = self._exe_command(
                    commit_cmd, cwd=mysql_bin_dir
                )

                if commit_success:
                    return True
                else:
                    error_msg = "\n".join([line for line in commit_output if line.strip()])
                    logger.error(f"MySQLäº‹åŠ¡æäº¤å¤±è´¥ - exit_code: {commit_exit_code}, é”™è¯¯: {error_msg}")
                    return False
            else:
                # å¯¼å…¥å¤±è´¥æ—¶å›æ»šäº‹åŠ¡
                rollback_cmd = (
                    f'{mysql_path} '
                    f'-h {self.mysql.db_host} '
                    f'-u {self.mysql.db_user} '
                    f'-p\'{self.mysql.db_pass}\' '
                    f'--port={self.mysql.db_port} '
                    f'--default-character-set=utf8 '
                    f'--execute="ROLLBACK; SET foreign_key_checks=1; SET unique_checks=1; SET autocommit=1;"'
                    f' {database}'
                )

                self._exe_command(rollback_cmd, cwd=mysql_bin_dir)

                error_msg = "\n".join([line for line in output if line.strip()])
                logger.error(f"MySQLå¯¼å…¥å¤±è´¥ - exit_code: {exit_code}, é”™è¯¯: {error_msg}")
                return False

        except Exception as e:
            logger.error(f"å¯¼å…¥æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            return False

    def restore_db_legacy(self, sql_file: str) -> bool:
        """å…¼å®¹æ—§ç‰ˆæœ¬çš„å•æ–‡ä»¶å¯¼å…¥æ–¹æ³•"""
        logger.warning("âš ï¸ ä½¿ç”¨æ—§ç‰ˆå¯¼å…¥æ–¹æ³•ï¼Œå»ºè®®æ”¹ç”¨æ–°çš„åˆ†æ­¥å¯¼å…¥æ–¹å¼")
        return self._execute_import(sql_file, None)
