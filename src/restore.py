import os
import sys
import time
import concurrent.futures
from pathlib import Path
from typing import List, Optional, Dict, Any
from colorama import Fore
from tqdm import tqdm
from base import BaseShell, Mysql
from logger_config import logger


class MyRestore(BaseShell):
    """
    MySQLæ•°æ®åº“æ¢å¤å·¥å…·ç±» - ä»SQLæ–‡ä»¶å¯¼å…¥åˆ°MySQLæ•°æ®åº“

    åŠŸèƒ½ç‰¹ç‚¹ï¼š
    1. æ”¯æŒå®Œæ•´æ•°æ®åº“æ¢å¤ï¼ˆç»“æ„+æ•°æ®ï¼‰
    2. æ”¯æŒå¹¶å‘å¯¼å…¥è¡¨æ•°æ®ï¼Œæé«˜æ¢å¤æ•ˆç‡
    3. æä¾›å®æ—¶è¿›åº¦æ˜¾ç¤ºå’Œè¯¦ç»†æ—¥å¿—è®°å½•
    4. æ”¯æŒå¤§æ–‡ä»¶åˆ†ç‰‡å¯¼å…¥
    5. å…·å¤‡é”™è¯¯å¤„ç†å’Œäº‹åŠ¡å›æ»šæœºåˆ¶

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        mysql = Mysql(host="localhost", user="root", password="123456", port=3306)
        restorer = MyRestore(mysql, threads=8)
        success = restorer.restore_db("mydb", "/backup/mydb_20240101")
    """

    def __init__(self, mysql: Mysql, threads: int = 8):
        """
        åˆå§‹åŒ–MyRestoreå®ä¾‹

        Args:
            mysql: Mysqlè¿æ¥é…ç½®å¯¹è±¡ï¼ŒåŒ…å«æ•°æ®åº“è¿æ¥ä¿¡æ¯
            threads: å¹¶å‘å¯¼å…¥çº¿ç¨‹æ•°ï¼Œé»˜è®¤ä¸º8
                   å»ºè®®æ ¹æ®CPUæ ¸å¿ƒæ•°å’Œç£ç›˜IOèƒ½åŠ›è°ƒæ•´
        """
        super().__init__()
        self.mysql = mysql  # MySQLè¿æ¥é…ç½®
        self.threads = threads  # å¹¶å‘çº¿ç¨‹æ•°

    def restore_db(self, database: str, dump_folder: str) -> bool:
        """
        ä»SQLæ–‡ä»¶å¯¼å…¥æ•´ä¸ªæ•°æ®åº“ï¼Œæä¾›å®Œæ•´çš„æ¢å¤æµç¨‹

        æ¢å¤æµç¨‹ï¼š
        1. æ£€æŸ¥å¹¶å¯¼å…¥æ•°æ®åº“ç»“æ„æ–‡ä»¶ï¼ˆdatabase.sqlï¼‰
        2. æ‰«ææ•°æ®æ–‡ä»¶å¤¹è·å–æ‰€æœ‰è¡¨æ•°æ®æ–‡ä»¶
        3. å¹¶å‘å¯¼å…¥æ‰€æœ‰è¡¨æ•°æ®æ–‡ä»¶

        Args:
            database: ç›®æ ‡æ•°æ®åº“åç§°
            dump_folder: å¤‡ä»½æ–‡ä»¶å¤¹è·¯å¾„ï¼Œç»“æ„å¦‚ä¸‹ï¼š
                        dump_folder/
                        â”œâ”€â”€ database.sql          # æ•°æ®åº“ç»“æ„æ–‡ä»¶
                        â””â”€â”€ database/             # æ•°æ®æ–‡ä»¶å¤¹
                            â”œâ”€â”€ table1.sql        # è¡¨æ•°æ®æ–‡ä»¶
                            â”œâ”€â”€ table2.sql
                            â””â”€â”€ table2_part2.sql  # åˆ†ç‰‡æ•°æ®æ–‡ä»¶

        Returns:
            bool: æ¢å¤æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False

        å¼‚å¸¸å¤„ç†ï¼š
            - æ–‡ä»¶ä¸å­˜åœ¨æ—¶è®°å½•é”™è¯¯æ—¥å¿—
            - ä»»ä½•æ­¥éª¤å¤±è´¥éƒ½ä¼šç»ˆæ­¢æ•´ä¸ªæ¢å¤è¿‡ç¨‹
            - æ‰€æœ‰å¼‚å¸¸éƒ½ä¼šè¢«æ•è·å¹¶è®°å½•
        """
        try:
            # 1. å¯¼å…¥æ•°æ®åº“ç»“æ„
            structure_file = os.path.join(dump_folder, f"{database}.sql")
            if not os.path.exists(structure_file):
                logger.error(f"æ•°æ®åº“ç»“æ„æ–‡ä»¶ä¸å­˜åœ¨: {structure_file}")
                return False

            if not self._import_structure(structure_file, database):
                return False

            # 2. è·å–æ‰€æœ‰è¡¨æ•°æ®æ–‡ä»¶
            db_data_folder = os.path.join(dump_folder, database)
            if not os.path.exists(db_data_folder):
                # æ•°æ®æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè¯´æ˜åªæœ‰ç»“æ„æ–‡ä»¶ï¼Œç›´æ¥è¿”å›æˆåŠŸ
                return True

            # æ”¶é›†æ‰€æœ‰æ•°æ®æ–‡ä»¶
            data_files = self._collect_data_files(db_data_folder)
            if not data_files:
                # æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œåªæœ‰ç»“æ„ï¼Œè¿”å›æˆåŠŸ
                return True

            # 3. å¹¶å‘å¯¼å…¥è¡¨æ•°æ®
            success_count = self._import_tables_data(database, data_files)

            if success_count == len(data_files):
                return True
            else:
                logger.error(f"å¯¼å…¥å¤±è´¥: {len(data_files) - success_count} ä¸ªæ–‡ä»¶å¯¼å…¥å¤±è´¥")
                return False

        except Exception as e:
            logger.error(f"å¯¼å…¥è¿‡ç¨‹å‘ç”Ÿé”™è¯¯ - æ•°æ®åº“: {database}, é”™è¯¯: {str(e)}")
            return False

    def _import_structure(self, structure_file: str, database: str) -> bool:
        """
        å¯¼å…¥æ•°æ®åº“ç»“æ„æ–‡ä»¶

        ç»“æ„æ–‡ä»¶åŒ…å«ï¼š
        - CREATE DATABASEè¯­å¥
        - æ‰€æœ‰è¡¨çš„CREATE TABLEè¯­å¥
        - ç´¢å¼•ã€çº¦æŸã€å­˜å‚¨è¿‡ç¨‹ç­‰

        Args:
            structure_file: ç»“æ„æ–‡ä»¶å®Œæ•´è·¯å¾„
            database: ç›®æ ‡æ•°æ®åº“åç§°

        Returns:
            bool: å¯¼å…¥æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
        """
        try:
            success, output = self._execute_import(structure_file, database, is_structure_file=True)
            if success:
                return True
            else:
                logger.error(f"æ•°æ®åº“ç»“æ„å¯¼å…¥å¤±è´¥ - æ•°æ®åº“: {database}, é”™è¯¯: {output}")
                return False
        except Exception as e:
            logger.error(f"æ•°æ®åº“ç»“æ„å¯¼å…¥å¤±è´¥ - æ•°æ®åº“: {database}, é”™è¯¯: {str(e)}")
            return False

    def _collect_data_files(self, db_data_folder: str) -> List[str]:
        """
        æ”¶é›†æ‰€æœ‰éœ€è¦å¯¼å…¥çš„æ•°æ®æ–‡ä»¶

        æ–‡ä»¶æ”¶é›†è§„åˆ™ï¼š
        1. åªæ”¶é›†.sqlåç¼€çš„æ–‡ä»¶
        2. æŒ‰æ–‡ä»¶åæ’åºï¼Œç¡®ä¿å¯¼å…¥é¡ºåºä¸€è‡´
        3. è·³è¿‡ç©ºæ–‡ä»¶
        4. æ”¯æŒåˆ†ç‰‡æ–‡ä»¶ï¼ˆå¦‚table_part1.sql, table_part2.sqlï¼‰

        Args:
            db_data_folder: æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„

        Returns:
            List[str]: æ•°æ®æ–‡ä»¶å®Œæ•´è·¯å¾„åˆ—è¡¨ï¼ŒæŒ‰æ–‡ä»¶åæ’åº
        """
        data_files = []

        for file in sorted(os.listdir(db_data_folder)):
            if file.endswith('.sql'):
                file_path = os.path.join(db_data_folder, file)
                file_size = os.path.getsize(file_path)

                if file_size > 0:
                    data_files.append(file_path)

        return data_files

    def _import_tables_data(self, database: str, data_files: List[str]) -> int:
        """
        å¹¶å‘å¯¼å…¥æ‰€æœ‰è¡¨æ•°æ®æ–‡ä»¶

        å¹¶å‘ç‰¹æ€§ï¼š
        1. ä½¿ç”¨ThreadPoolExecutorç®¡ç†çº¿ç¨‹æ± 
        2. å®æ—¶è¿›åº¦æ¡æ˜¾ç¤ºï¼ˆtqdmï¼‰
        3. åŠ¨æ€é€Ÿåº¦æ˜¾ç¤ºï¼ˆMB/sï¼‰
        4. å¤±è´¥æ–‡ä»¶å•ç‹¬è®°å½•

        Args:
            database: ç›®æ ‡æ•°æ®åº“åç§°
            data_files: æ•°æ®æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            int: æˆåŠŸå¯¼å…¥çš„æ–‡ä»¶æ•°é‡
        """
        success_count = 0
        failed_files = []
        imported_total_size = 0.0  # å·²å¯¼å…¥çš„æ€»å¤§å°ï¼ˆMBï¼‰
        import_start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´

        # ä½¿ç”¨tqdmåˆ›å»ºè¿›åº¦æ¡
        with tqdm(
            total=len(data_files),
            desc=f"{Fore.MAGENTA}ğŸ“Š å¯¼å…¥: [{database}] æ•°æ®åº“",
            unit="æ–‡ä»¶",
            dynamic_ncols=True,  # è‡ªåŠ¨è°ƒæ•´å®½åº¦
            disable=False,
            file=sys.stdout,
            ascii=True,
            miniters=1,
            mininterval=0.1,
            position=0,
            leave=True
        ) as pbar:

            # è¿›åº¦æ›´æ–°å›è°ƒå‡½æ•°
            def update_progress(result, file_name):
                nonlocal imported_total_size
                # è®¡ç®—ä»å¼€å§‹åˆ°ç°åœ¨çš„æ•´ä½“å¹³å‡é€Ÿåº¦
                elapsed_time = time.time() - import_start_time

                if result['success']:
                    imported_total_size += result['size_mb']
                    avg_speed = f"{imported_total_size / elapsed_time:.1f}MB/s" if elapsed_time > 0 else "0.0MB/s"
                    pbar.set_postfix_str(
                        f"âœ“ {os.path.basename(file_name)} "
                        f"({result['size_mb']:.1f}MB)   {avg_speed} "
                        f"| {imported_total_size:.1f}MB"
                    )
                else:
                    imported_total_size += result['size_mb']
                    avg_speed = f"{imported_total_size / elapsed_time:.1f}MB/s" if elapsed_time > 0 else "0.0MB/s"
                    pbar.set_postfix_str(
                        f"âœ— {os.path.basename(file_name)}   {avg_speed} | {imported_total_size:.1f}MB"
                    )
                pbar.update(1)
                return result

            # åˆ›å»ºçº¿ç¨‹æ± æ‰§è¡Œå¹¶å‘å¯¼å…¥
            with concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as pool:
                # æäº¤æ‰€æœ‰å¯¼å…¥ä»»åŠ¡
                futures = []
                for sql_file in data_files:
                    future = pool.submit(
                        self._import_single_table,
                        sql_file,
                        database,
                    )
                    # æ·»åŠ å›è°ƒæ¥æ›´æ–°è¿›åº¦
                    future.add_done_callback(
                        lambda f, f_path=sql_file: update_progress(f.result(), f_path)
                    )
                    futures.append(future)

                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                concurrent.futures.wait(futures)

                # æ”¶é›†æœ€ç»ˆç»“æœ
                for future, sql_file in zip(futures, data_files):
                    try:
                        result = future.result()
                        if result['success']:
                            success_count += 1
                        else:
                            failed_files.append(os.path.basename(sql_file))
                            logger.error(
                                f"æ–‡ä»¶å¯¼å…¥å¤±è´¥ - æ–‡ä»¶: {os.path.basename(sql_file)}, "
                                f"é”™è¯¯: {result['error']}"
                            )
                    except Exception as e:
                        failed_files.append(os.path.basename(sql_file))
                        logger.error(
                            f"æ–‡ä»¶å¯¼å…¥å¼‚å¸¸ - æ–‡ä»¶: {os.path.basename(sql_file)}, "
                            f"é”™è¯¯: {str(e)}"
                        )

        # æ±‡æ€»å¤±è´¥æ–‡ä»¶
        if failed_files:
            logger.error(f"å¯¼å…¥å¤±è´¥æ–‡ä»¶åˆ—è¡¨: {', '.join(failed_files)}")

        return success_count

    def _import_single_table(self, sql_file: str, database: str) -> Dict[str, Any]:
        """
        å¯¼å…¥å•ä¸ªè¡¨çš„æ•°æ®æ–‡ä»¶

        æ”¯æŒç‰¹æ€§ï¼š
        1. è®¡ç®—æ–‡ä»¶å¤§å°å’Œå¯¼å…¥è€—æ—¶
        2. è¿”å›è¯¦ç»†çš„å¯¼å…¥ç»“æœä¿¡æ¯
        3. å¼‚å¸¸æ•è·å’Œé”™è¯¯ä¿¡æ¯è®°å½•

        Args:
            sql_file: SQLæ–‡ä»¶å®Œæ•´è·¯å¾„
            database: ç›®æ ‡æ•°æ®åº“åç§°

        Returns:
            Dict[str, Any]: å¯¼å…¥ç»“æœï¼ŒåŒ…å«ï¼š
                - success: æ˜¯å¦æˆåŠŸ
                - duration: è€—æ—¶ï¼ˆç§’ï¼‰
                - size_mb: æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
                - error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        start_time = time.time()

        try:
            file_size = os.path.getsize(sql_file)
            file_size_mb = file_size / 1024 / 1024

            success, output = self._execute_import(sql_file, database, is_structure_file=False)

            return {
                'success': success,
                'duration': time.time() - start_time,
                'size_mb': file_size_mb,
                'error': None if success else output
            }

        except Exception as e:
            return {
                'success': False,
                'duration': time.time() - start_time,
                'size_mb': 0,
                'error': str(e)
            }

    def _execute_import(self, sql_file: str, database: str, is_structure_file: bool = False) -> tuple[bool, str]:
        """
        æ‰§è¡Œå•ä¸ªSQLæ–‡ä»¶çš„å¯¼å…¥

        å¯¼å…¥ä¼˜åŒ–ï¼š
        1. åŒºåˆ†ç»“æ„æ–‡ä»¶å’Œæ•°æ®æ–‡ä»¶çš„å¤„ç†æ–¹å¼
        2. ç»“æ„æ–‡ä»¶ï¼šä¸æŒ‡å®šæ•°æ®åº“ï¼Œè®©SQLæ–‡ä»¶ä¸­çš„CREATE DATABASEç”Ÿæ•ˆ
        3. æ•°æ®æ–‡ä»¶ï¼šæŒ‡å®šå…·ä½“æ•°æ®åº“è¿›è¡Œå¯¼å…¥
        4. ç¦ç”¨è‡ªåŠ¨æäº¤ï¼Œæé«˜æ‰¹é‡å¯¼å…¥æ€§èƒ½
        5. ç¦ç”¨å¤–é”®æ£€æŸ¥ï¼Œé¿å…çº¦æŸå†²çª

        äº‹åŠ¡ç®¡ç†ï¼š
        - å¯¼å…¥å‰ï¼šç¦ç”¨çº¦æŸæ£€æŸ¥
        - å¯¼å…¥åï¼šæˆåŠŸåˆ™æäº¤äº‹åŠ¡ï¼Œå¤±è´¥åˆ™å›æ»š
        - æ¸…ç†ï¼šæ¢å¤æ‰€æœ‰MySQLè®¾ç½®

        Args:
            sql_file: SQLæ–‡ä»¶å®Œæ•´è·¯å¾„
            database: ç›®æ ‡æ•°æ®åº“åç§°
            is_structure_file: æ˜¯å¦ä¸ºç»“æ„æ–‡ä»¶ï¼ˆåŒ…å«CREATE DATABASEè¯­å¥ï¼‰

        Returns:
            bool: å¯¼å…¥æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
        """
        try:
            mysql_exe = self.get_mysql_exe()
            mysql_bin_dir = self.get_mysql_bin_dir()

            # æ„å»ºåŸºç¡€mysqlå‘½ä»¤
            base_cmd = (
                f'{mysql_exe} '
                f'-h {self.mysql.db_host} '
                f'-u {self.mysql.db_user} '
                f'-p\'{self.mysql.db_pass}\' '
                f'--port={self.mysql.db_port} '
                f'--ssl-mode=DISABLED '
                f'--protocol=TCP '
                f'--max-allowed-packet=2048M '
                f'--net-buffer-length=16777216 '
            )

            # æ•°æ®æ–‡ä»¶ï¼šæŒ‡å®šå…·ä½“æ•°æ®åº“ï¼Œå¹¶æ·»åŠ åˆå§‹åŒ–å‘½ä»¤
            init_commands = [
                "SET autocommit=0",
                "SET foreign_key_checks=0",
                "SET unique_checks=0",
                "SET SESSION innodb_lock_wait_timeout=1800",
            ]

            init_command_str = ";".join(init_commands)

            # æ ¹æ®æ–‡ä»¶ç±»å‹æ„å»ºå‘½ä»¤
            if is_structure_file:
                # ç»“æ„æ–‡ä»¶ï¼šä¸æŒ‡å®šæ•°æ®åº“ï¼Œè®©SQLæ–‡ä»¶ä¸­çš„CREATE DATABASEç”Ÿæ•ˆ
                cmd = f'{base_cmd} --init-command="{init_command_str}"'
            else:
                cmd = f'{base_cmd} --init-command="{init_command_str}" {database}'

            import_command = f'{cmd} < "{sql_file}"'

            # æ‰§è¡Œå¯¼å…¥å‘½ä»¤
            success, exit_code, output = self._exe_command(
                import_command, cwd=mysql_bin_dir
            )

            if success:
                return True, ""
            else:
                error_msg = "\n".join([line for line in output if line.strip()])
                return False, error_msg

        except Exception as e:
            logger.error(f"å¯¼å…¥æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            return False, str(e)
